{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zipp 0.6.0\n",
      "zict 1.0.0\n",
      "xmltodict 0.12.0\n",
      "xlwt 1.3.0\n",
      "xlwings 0.15.10\n",
      "XlsxWriter 1.2.1\n",
      "xlrd 1.2.0\n",
      "wrapt 1.11.2\n",
      "wincertstore 0.2\n",
      "win-unicode-console 0.5\n",
      "win-inet-pton 1.1.0\n",
      "widgetsnbextension 3.5.1\n",
      "wheel 0.33.6\n",
      "Werkzeug 0.16.0\n",
      "websocket-client 0.48.0\n",
      "webencodings 0.5.1\n",
      "wcwidth 0.1.7\n",
      "vega-datasets 0.8.0\n",
      "urllib3 1.24.2\n",
      "unicodecsv 0.14.1\n",
      "typing-extensions 3.7.4.3\n",
      "traitlets 4.3.3\n",
      "tqdm 4.36.1\n",
      "tornado 6.0.3\n",
      "toolz 0.10.0\n",
      "testpath 0.4.2\n",
      "terminado 0.8.2\n",
      "termcolor 1.1.0\n",
      "tensorflow 1.15.0\n",
      "tensorflow-estimator 1.15.1\n",
      "tensorboard 1.15.0\n",
      "tblib 1.4.0\n",
      "tables 3.5.2\n",
      "sympy 1.4\n",
      "statsmodels 0.10.1\n",
      "sqlparse 0.3.0\n",
      "SQLAlchemy 1.3.9\n",
      "spyder 3.3.6\n",
      "spyder-kernels 0.5.2\n",
      "sphinxcontrib-websupport 1.1.2\n",
      "sphinxcontrib-serializinghtml 1.1.3\n",
      "sphinxcontrib-qthelp 1.0.2\n",
      "sphinxcontrib-jsmath 1.0.1\n",
      "sphinxcontrib-htmlhelp 1.0.2\n",
      "sphinxcontrib-devhelp 1.0.1\n",
      "sphinxcontrib-applehelp 1.0.1\n",
      "Sphinx 2.2.0\n",
      "speedtest-cli 2.1.2\n",
      "soupsieve 1.9.3\n",
      "sortedcontainers 2.1.0\n",
      "sortedcollections 1.1.2\n",
      "snowballstemmer 2.0.0\n",
      "sklearn 0.0\n",
      "six 1.12.0\n",
      "singledispatch 3.4.0.3\n",
      "simplegeneric 0.8.1\n",
      "setuptools 41.4.0\n",
      "Send2Trash 1.5.0\n",
      "selenium 3.141.0\n",
      "seaborn 0.9.0\n",
      "scipy 1.3.1\n",
      "scikit-learn 0.21.3\n",
      "scikit-image 0.15.0\n",
      "Sastrawi 1.0.1\n",
      "ruamel-yaml 0.15.46\n",
      "rope 0.14.0\n",
      "requests 2.22.0\n",
      "QtPy 1.9.0\n",
      "qtconsole 4.5.5\n",
      "QtAwesome 0.6.0\n",
      "pyzmq 18.1.0\n",
      "PyYAML 5.1.2\n",
      "pywinpty 0.5.5\n",
      "pywin32 223\n",
      "PyWavelets 1.0.3\n",
      "pytz 2019.3\n",
      "python-dateutil 2.8.0\n",
      "pytest 5.2.1\n",
      "pytest-remotedata 0.3.2\n",
      "pytest-openfiles 0.4.0\n",
      "pytest-doctestplus 0.4.0\n",
      "pytest-astropy 0.5.0\n",
      "pytest-arraydiff 0.3\n",
      "PySocks 1.7.1\n",
      "pyrsistent 0.15.4\n",
      "pyreadline 2.1\n",
      "pyparsing 2.4.2\n",
      "pyOpenSSL 19.0.0\n",
      "pyodbc 4.0.27\n",
      "pylint 2.4.2\n",
      "PyJWT 1.7.1\n",
      "Pygments 2.4.2\n",
      "pyflakes 2.1.1\n",
      "pycurl 7.43.0.3\n",
      "pycrypto 2.6.1\n",
      "pycparser 2.19\n",
      "pycosat 0.6.3\n",
      "pycodestyle 2.5.0\n",
      "py 1.8.0\n",
      "psutil 5.6.3\n",
      "protobuf 3.14.0\n",
      "prompt-toolkit 2.0.10\n",
      "prometheus-client 0.7.1\n",
      "ply 3.11\n",
      "pluggy 0.13.0\n",
      "pkginfo 1.5.0.1\n",
      "pip 19.2.3\n",
      "Pillow 6.2.0\n",
      "pickleshare 0.7.5\n",
      "pep8 1.7.1\n",
      "patsy 0.5.1\n",
      "pathlib2 2.3.5\n",
      "path.py 12.0.1\n",
      "partd 1.0.0\n",
      "parso 0.5.1\n",
      "pandocfilters 1.4.2\n",
      "pandas 0.25.1\n",
      "packaging 19.2\n",
      "opt-einsum 3.1.0\n",
      "openpyxl 3.0.0\n",
      "opencv-python 4.1.2.30\n",
      "olefile 0.46\n",
      "numpydoc 0.9.1\n",
      "numpy 1.16.5\n",
      "numexpr 2.7.0\n",
      "numba 0.45.1\n",
      "notebook 6.0.1\n",
      "nose 1.3.7\n",
      "nltk 3.4.5\n",
      "networkx 2.3\n",
      "nbformat 4.4.0\n",
      "nbconvert 5.6.0\n",
      "navigator-updater 0.2.1\n",
      "multipledispatch 0.6.0\n",
      "msgpack 0.6.1\n",
      "mpmath 1.1.0\n",
      "more-itertools 7.2.0\n",
      "mock 3.0.5\n",
      "mkl-service 2.3.0\n",
      "mkl-random 1.1.0\n",
      "mkl-fft 1.0.14\n",
      "mistune 0.8.4\n",
      "menuinst 1.4.16\n",
      "mds 0.0.6\n",
      "mccabe 0.6.1\n",
      "matplotlib 3.1.1\n",
      "MarkupSafe 1.1.1\n",
      "Markdown 3.3.4\n",
      "lxml 4.4.1\n",
      "locket 0.2.0\n",
      "llvmlite 0.29.0\n",
      "libarchive-c 2.8\n",
      "lazy-object-proxy 1.4.2\n",
      "kiwisolver 1.1.0\n",
      "keyring 18.0.0\n",
      "Keras 2.3.1\n",
      "Keras-Preprocessing 1.1.2\n",
      "Keras-Applications 1.0.8\n",
      "jupyterlab 1.1.4\n",
      "jupyterlab-server 1.0.6\n",
      "jupyter 1.0.0\n",
      "jupyter-core 4.5.0\n",
      "jupyter-console 6.0.0\n",
      "jupyter-client 5.3.3\n",
      "jsonschema 3.0.2\n",
      "json5 0.8.5\n",
      "joblib 0.13.2\n",
      "Jinja2 2.10.3\n",
      "jedi 0.15.1\n",
      "jdcal 1.4.1\n",
      "itsdangerous 1.1.0\n",
      "isort 4.3.21\n",
      "ipywidgets 7.5.1\n",
      "ipython 7.8.0\n",
      "ipython-genutils 0.2.0\n",
      "ipykernel 5.1.2\n",
      "importlib-metadata 3.7.3\n",
      "imagesize 1.1.0\n",
      "imageio 2.6.0\n",
      "idna 2.8\n",
      "ibm-watson 4.7.1\n",
      "ibm-cloud-sdk-core 1.7.3\n",
      "html5lib 1.0.1\n",
      "HeapDict 1.0.1\n",
      "h5py 2.9.0\n",
      "grpcio 1.16.1\n",
      "greenlet 0.4.15\n",
      "google-pasta 0.2.0\n",
      "glob2 0.7\n",
      "gevent 1.4.0\n",
      "gast 0.2.2\n",
      "future 0.18.2\n",
      "fsspec 0.5.2\n",
      "Flask 1.1.1\n",
      "filelock 3.0.12\n",
      "fastcache 1.1.0\n",
      "et-xmlfile 1.0.1\n",
      "entrypoints 0.3\n",
      "docutils 0.15.2\n",
      "Django 3.0.3\n",
      "distributed 2.5.2\n",
      "defusedxml 0.6.0\n",
      "decorator 4.4.0\n",
      "dask 2.5.2\n",
      "cytoolz 0.10.0\n",
      "Cython 0.29.13\n",
      "cycler 0.10.0\n",
      "cryptography 2.7\n",
      "contextlib2 0.6.0\n",
      "conda 4.9.2\n",
      "conda-verify 3.4.2\n",
      "conda-package-handling 1.7.2\n",
      "conda-build 3.21.4\n",
      "comtypes 1.1.7\n",
      "colorama 0.4.1\n",
      "clyent 1.2.2\n",
      "cloudpickle 1.2.2\n",
      "Click 7.0\n",
      "chardet 3.0.4\n",
      "cffi 1.12.3\n",
      "certifi 2019.9.11\n",
      "Bottleneck 1.2.1\n",
      "bottle 0.12.19\n",
      "boto 2.49.0\n",
      "bokeh 1.3.4\n",
      "bleach 3.1.0\n",
      "bkcharts 0.2\n",
      "bitarray 1.0.1\n",
      "beautifulsoup4 4.8.0\n",
      "backports.weakref 1.0.post1\n",
      "backports.tempfile 1.0\n",
      "backports.shutil-get-terminal-size 1.0.0\n",
      "backports.os 0.1.1\n",
      "backports.functools-lru-cache 1.6.1\n",
      "backcall 0.1.0\n",
      "Babel 2.7.0\n",
      "attrs 19.2.0\n",
      "atomicwrites 1.3.0\n",
      "astropy 3.2.1\n",
      "astroid 2.3.1\n",
      "astor 0.8.1\n",
      "asn1crypto 1.0.1\n",
      "asgiref 3.2.3\n",
      "anaconda-project 0.8.3\n",
      "anaconda-navigator 1.10.0\n",
      "anaconda-client 1.7.2\n",
      "alabaster 0.7.12\n",
      "absl-py 0.12.0\n"
     ]
    }
   ],
   "source": [
    "dists = [d for d in pkg_resources.working_set]\n",
    "for i in dists:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "string01 = \"Budi dan Badu bermain bola di sekolah\"\n",
    "string02 = \"Apakah Romi dan Julia saling mencintai saat mereka berjumpa di persimpangan jalan?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_clean(text):\n",
    "    \n",
    "    #tokenisasi\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word\n",
    "        in nltk.word_tokenize(sent)]\n",
    "    \n",
    "    #clean token from numeric and other character like punctuation\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "            \n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budi dan Badu bermain bola di sekolah\n",
      "['budi', 'dan', 'badu', 'bermain', 'bola', 'di', 'sekolah']\n"
     ]
    }
   ],
   "source": [
    "result01 = tokenize_clean(string01)\n",
    "print(string01)\n",
    "print(result01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apakah Romi dan Julia saling mencintai saat mereka berjumpa di persimpangan jalan?\n",
      "['apakah', 'romi', 'dan', 'julia', 'saling', 'mencintai', 'saat', 'mereka', 'berjumpa', 'di', 'persimpangan', 'jalan']\n"
     ]
    }
   ],
   "source": [
    "result02 = tokenize_clean(string02)\n",
    "print(string02)\n",
    "print(result02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Fajri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Fajri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('indonesian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ada',\n",
       " 'adalah',\n",
       " 'adanya',\n",
       " 'adapun',\n",
       " 'agak',\n",
       " 'agaknya',\n",
       " 'agar',\n",
       " 'akan',\n",
       " 'akankah',\n",
       " 'akhir',\n",
       " 'akhiri',\n",
       " 'akhirnya',\n",
       " 'aku',\n",
       " 'akulah',\n",
       " 'amat',\n",
       " 'amatlah',\n",
       " 'anda',\n",
       " 'andalah',\n",
       " 'antar',\n",
       " 'antara',\n",
       " 'antaranya',\n",
       " 'apa',\n",
       " 'apaan',\n",
       " 'apabila',\n",
       " 'apakah',\n",
       " 'apalagi',\n",
       " 'apatah',\n",
       " 'artinya',\n",
       " 'asal',\n",
       " 'asalkan',\n",
       " 'atas',\n",
       " 'atau',\n",
       " 'ataukah',\n",
       " 'ataupun',\n",
       " 'awal',\n",
       " 'awalnya',\n",
       " 'bagai',\n",
       " 'bagaikan',\n",
       " 'bagaimana',\n",
       " 'bagaimanakah',\n",
       " 'bagaimanapun',\n",
       " 'bagi',\n",
       " 'bagian',\n",
       " 'bahkan',\n",
       " 'bahwa',\n",
       " 'bahwasanya',\n",
       " 'baik',\n",
       " 'bakal',\n",
       " 'bakalan',\n",
       " 'balik',\n",
       " 'banyak',\n",
       " 'bapak',\n",
       " 'baru',\n",
       " 'bawah',\n",
       " 'beberapa',\n",
       " 'begini',\n",
       " 'beginian',\n",
       " 'beginikah',\n",
       " 'beginilah',\n",
       " 'begitu',\n",
       " 'begitukah',\n",
       " 'begitulah',\n",
       " 'begitupun',\n",
       " 'bekerja',\n",
       " 'belakang',\n",
       " 'belakangan',\n",
       " 'belum',\n",
       " 'belumlah',\n",
       " 'benar',\n",
       " 'benarkah',\n",
       " 'benarlah',\n",
       " 'berada',\n",
       " 'berakhir',\n",
       " 'berakhirlah',\n",
       " 'berakhirnya',\n",
       " 'berapa',\n",
       " 'berapakah',\n",
       " 'berapalah',\n",
       " 'berapapun',\n",
       " 'berarti',\n",
       " 'berawal',\n",
       " 'berbagai',\n",
       " 'berdatangan',\n",
       " 'beri',\n",
       " 'berikan',\n",
       " 'berikut',\n",
       " 'berikutnya',\n",
       " 'berjumlah',\n",
       " 'berkali-kali',\n",
       " 'berkata',\n",
       " 'berkehendak',\n",
       " 'berkeinginan',\n",
       " 'berkenaan',\n",
       " 'berlainan',\n",
       " 'berlalu',\n",
       " 'berlangsung',\n",
       " 'berlebihan',\n",
       " 'bermacam',\n",
       " 'bermacam-macam',\n",
       " 'bermaksud',\n",
       " 'bermula',\n",
       " 'bersama',\n",
       " 'bersama-sama',\n",
       " 'bersiap',\n",
       " 'bersiap-siap',\n",
       " 'bertanya',\n",
       " 'bertanya-tanya',\n",
       " 'berturut',\n",
       " 'berturut-turut',\n",
       " 'bertutur',\n",
       " 'berujar',\n",
       " 'berupa',\n",
       " 'besar',\n",
       " 'betul',\n",
       " 'betulkah',\n",
       " 'biasa',\n",
       " 'biasanya',\n",
       " 'bila',\n",
       " 'bilakah',\n",
       " 'bisa',\n",
       " 'bisakah',\n",
       " 'boleh',\n",
       " 'bolehkah',\n",
       " 'bolehlah',\n",
       " 'buat',\n",
       " 'bukan',\n",
       " 'bukankah',\n",
       " 'bukanlah',\n",
       " 'bukannya',\n",
       " 'bulan',\n",
       " 'bung',\n",
       " 'cara',\n",
       " 'caranya',\n",
       " 'cukup',\n",
       " 'cukupkah',\n",
       " 'cukuplah',\n",
       " 'cuma',\n",
       " 'dahulu',\n",
       " 'dalam',\n",
       " 'dan',\n",
       " 'dapat',\n",
       " 'dari',\n",
       " 'daripada',\n",
       " 'datang',\n",
       " 'dekat',\n",
       " 'demi',\n",
       " 'demikian',\n",
       " 'demikianlah',\n",
       " 'dengan',\n",
       " 'depan',\n",
       " 'di',\n",
       " 'dia',\n",
       " 'diakhiri',\n",
       " 'diakhirinya',\n",
       " 'dialah',\n",
       " 'diantara',\n",
       " 'diantaranya',\n",
       " 'diberi',\n",
       " 'diberikan',\n",
       " 'diberikannya',\n",
       " 'dibuat',\n",
       " 'dibuatnya',\n",
       " 'didapat',\n",
       " 'didatangkan',\n",
       " 'digunakan',\n",
       " 'diibaratkan',\n",
       " 'diibaratkannya',\n",
       " 'diingat',\n",
       " 'diingatkan',\n",
       " 'diinginkan',\n",
       " 'dijawab',\n",
       " 'dijelaskan',\n",
       " 'dijelaskannya',\n",
       " 'dikarenakan',\n",
       " 'dikatakan',\n",
       " 'dikatakannya',\n",
       " 'dikerjakan',\n",
       " 'diketahui',\n",
       " 'diketahuinya',\n",
       " 'dikira',\n",
       " 'dilakukan',\n",
       " 'dilalui',\n",
       " 'dilihat',\n",
       " 'dimaksud',\n",
       " 'dimaksudkan',\n",
       " 'dimaksudkannya',\n",
       " 'dimaksudnya',\n",
       " 'diminta',\n",
       " 'dimintai',\n",
       " 'dimisalkan',\n",
       " 'dimulai',\n",
       " 'dimulailah',\n",
       " 'dimulainya',\n",
       " 'dimungkinkan',\n",
       " 'dini',\n",
       " 'dipastikan',\n",
       " 'diperbuat',\n",
       " 'diperbuatnya',\n",
       " 'dipergunakan',\n",
       " 'diperkirakan',\n",
       " 'diperlihatkan',\n",
       " 'diperlukan',\n",
       " 'diperlukannya',\n",
       " 'dipersoalkan',\n",
       " 'dipertanyakan',\n",
       " 'dipunyai',\n",
       " 'diri',\n",
       " 'dirinya',\n",
       " 'disampaikan',\n",
       " 'disebut',\n",
       " 'disebutkan',\n",
       " 'disebutkannya',\n",
       " 'disini',\n",
       " 'disinilah',\n",
       " 'ditambahkan',\n",
       " 'ditandaskan',\n",
       " 'ditanya',\n",
       " 'ditanyai',\n",
       " 'ditanyakan',\n",
       " 'ditegaskan',\n",
       " 'ditujukan',\n",
       " 'ditunjuk',\n",
       " 'ditunjuki',\n",
       " 'ditunjukkan',\n",
       " 'ditunjukkannya',\n",
       " 'ditunjuknya',\n",
       " 'dituturkan',\n",
       " 'dituturkannya',\n",
       " 'diucapkan',\n",
       " 'diucapkannya',\n",
       " 'diungkapkan',\n",
       " 'dong',\n",
       " 'dua',\n",
       " 'dulu',\n",
       " 'empat',\n",
       " 'enggak',\n",
       " 'enggaknya',\n",
       " 'entah',\n",
       " 'entahlah',\n",
       " 'guna',\n",
       " 'gunakan',\n",
       " 'hal',\n",
       " 'hampir',\n",
       " 'hanya',\n",
       " 'hanyalah',\n",
       " 'hari',\n",
       " 'harus',\n",
       " 'haruslah',\n",
       " 'harusnya',\n",
       " 'hendak',\n",
       " 'hendaklah',\n",
       " 'hendaknya',\n",
       " 'hingga',\n",
       " 'ia',\n",
       " 'ialah',\n",
       " 'ibarat',\n",
       " 'ibaratkan',\n",
       " 'ibaratnya',\n",
       " 'ibu',\n",
       " 'ikut',\n",
       " 'ingat',\n",
       " 'ingat-ingat',\n",
       " 'ingin',\n",
       " 'inginkah',\n",
       " 'inginkan',\n",
       " 'ini',\n",
       " 'inikah',\n",
       " 'inilah',\n",
       " 'itu',\n",
       " 'itukah',\n",
       " 'itulah',\n",
       " 'jadi',\n",
       " 'jadilah',\n",
       " 'jadinya',\n",
       " 'jangan',\n",
       " 'jangankan',\n",
       " 'janganlah',\n",
       " 'jauh',\n",
       " 'jawab',\n",
       " 'jawaban',\n",
       " 'jawabnya',\n",
       " 'jelas',\n",
       " 'jelaskan',\n",
       " 'jelaslah',\n",
       " 'jelasnya',\n",
       " 'jika',\n",
       " 'jikalau',\n",
       " 'juga',\n",
       " 'jumlah',\n",
       " 'jumlahnya',\n",
       " 'justru',\n",
       " 'kala',\n",
       " 'kalau',\n",
       " 'kalaulah',\n",
       " 'kalaupun',\n",
       " 'kalian',\n",
       " 'kami',\n",
       " 'kamilah',\n",
       " 'kamu',\n",
       " 'kamulah',\n",
       " 'kan',\n",
       " 'kapan',\n",
       " 'kapankah',\n",
       " 'kapanpun',\n",
       " 'karena',\n",
       " 'karenanya',\n",
       " 'kasus',\n",
       " 'kata',\n",
       " 'katakan',\n",
       " 'katakanlah',\n",
       " 'katanya',\n",
       " 'ke',\n",
       " 'keadaan',\n",
       " 'kebetulan',\n",
       " 'kecil',\n",
       " 'kedua',\n",
       " 'keduanya',\n",
       " 'keinginan',\n",
       " 'kelamaan',\n",
       " 'kelihatan',\n",
       " 'kelihatannya',\n",
       " 'kelima',\n",
       " 'keluar',\n",
       " 'kembali',\n",
       " 'kemudian',\n",
       " 'kemungkinan',\n",
       " 'kemungkinannya',\n",
       " 'kenapa',\n",
       " 'kepada',\n",
       " 'kepadanya',\n",
       " 'kesampaian',\n",
       " 'keseluruhan',\n",
       " 'keseluruhannya',\n",
       " 'keterlaluan',\n",
       " 'ketika',\n",
       " 'khususnya',\n",
       " 'kini',\n",
       " 'kinilah',\n",
       " 'kira',\n",
       " 'kira-kira',\n",
       " 'kiranya',\n",
       " 'kita',\n",
       " 'kitalah',\n",
       " 'kok',\n",
       " 'kurang',\n",
       " 'lagi',\n",
       " 'lagian',\n",
       " 'lah',\n",
       " 'lain',\n",
       " 'lainnya',\n",
       " 'lalu',\n",
       " 'lama',\n",
       " 'lamanya',\n",
       " 'lanjut',\n",
       " 'lanjutnya',\n",
       " 'lebih',\n",
       " 'lewat',\n",
       " 'lima',\n",
       " 'luar',\n",
       " 'macam',\n",
       " 'maka',\n",
       " 'makanya',\n",
       " 'makin',\n",
       " 'malah',\n",
       " 'malahan',\n",
       " 'mampu',\n",
       " 'mampukah',\n",
       " 'mana',\n",
       " 'manakala',\n",
       " 'manalagi',\n",
       " 'masa',\n",
       " 'masalah',\n",
       " 'masalahnya',\n",
       " 'masih',\n",
       " 'masihkah',\n",
       " 'masing',\n",
       " 'masing-masing',\n",
       " 'mau',\n",
       " 'maupun',\n",
       " 'melainkan',\n",
       " 'melakukan',\n",
       " 'melalui',\n",
       " 'melihat',\n",
       " 'melihatnya',\n",
       " 'memang',\n",
       " 'memastikan',\n",
       " 'memberi',\n",
       " 'memberikan',\n",
       " 'membuat',\n",
       " 'memerlukan',\n",
       " 'memihak',\n",
       " 'meminta',\n",
       " 'memintakan',\n",
       " 'memisalkan',\n",
       " 'memperbuat',\n",
       " 'mempergunakan',\n",
       " 'memperkirakan',\n",
       " 'memperlihatkan',\n",
       " 'mempersiapkan',\n",
       " 'mempersoalkan',\n",
       " 'mempertanyakan',\n",
       " 'mempunyai',\n",
       " 'memulai',\n",
       " 'memungkinkan',\n",
       " 'menaiki',\n",
       " 'menambahkan',\n",
       " 'menandaskan',\n",
       " 'menanti',\n",
       " 'menanti-nanti',\n",
       " 'menantikan',\n",
       " 'menanya',\n",
       " 'menanyai',\n",
       " 'menanyakan',\n",
       " 'mendapat',\n",
       " 'mendapatkan',\n",
       " 'mendatang',\n",
       " 'mendatangi',\n",
       " 'mendatangkan',\n",
       " 'menegaskan',\n",
       " 'mengakhiri',\n",
       " 'mengapa',\n",
       " 'mengatakan',\n",
       " 'mengatakannya',\n",
       " 'mengenai',\n",
       " 'mengerjakan',\n",
       " 'mengetahui',\n",
       " 'menggunakan',\n",
       " 'menghendaki',\n",
       " 'mengibaratkan',\n",
       " 'mengibaratkannya',\n",
       " 'mengingat',\n",
       " 'mengingatkan',\n",
       " 'menginginkan',\n",
       " 'mengira',\n",
       " 'mengucapkan',\n",
       " 'mengucapkannya',\n",
       " 'mengungkapkan',\n",
       " 'menjadi',\n",
       " 'menjawab',\n",
       " 'menjelaskan',\n",
       " 'menuju',\n",
       " 'menunjuk',\n",
       " 'menunjuki',\n",
       " 'menunjukkan',\n",
       " 'menunjuknya',\n",
       " 'menurut',\n",
       " 'menuturkan',\n",
       " 'menyampaikan',\n",
       " 'menyangkut',\n",
       " 'menyatakan',\n",
       " 'menyebutkan',\n",
       " 'menyeluruh',\n",
       " 'menyiapkan',\n",
       " 'merasa',\n",
       " 'mereka',\n",
       " 'merekalah',\n",
       " 'merupakan',\n",
       " 'meski',\n",
       " 'meskipun',\n",
       " 'meyakini',\n",
       " 'meyakinkan',\n",
       " 'minta',\n",
       " 'mirip',\n",
       " 'misal',\n",
       " 'misalkan',\n",
       " 'misalnya',\n",
       " 'mula',\n",
       " 'mulai',\n",
       " 'mulailah',\n",
       " 'mulanya',\n",
       " 'mungkin',\n",
       " 'mungkinkah',\n",
       " 'nah',\n",
       " 'naik',\n",
       " 'namun',\n",
       " 'nanti',\n",
       " 'nantinya',\n",
       " 'nyaris',\n",
       " 'nyatanya',\n",
       " 'oleh',\n",
       " 'olehnya',\n",
       " 'pada',\n",
       " 'padahal',\n",
       " 'padanya',\n",
       " 'pak',\n",
       " 'paling',\n",
       " 'panjang',\n",
       " 'pantas',\n",
       " 'para',\n",
       " 'pasti',\n",
       " 'pastilah',\n",
       " 'penting',\n",
       " 'pentingnya',\n",
       " 'per',\n",
       " 'percuma',\n",
       " 'perlu',\n",
       " 'perlukah',\n",
       " 'perlunya',\n",
       " 'pernah',\n",
       " 'persoalan',\n",
       " 'pertama',\n",
       " 'pertama-tama',\n",
       " 'pertanyaan',\n",
       " 'pertanyakan',\n",
       " 'pihak',\n",
       " 'pihaknya',\n",
       " 'pukul',\n",
       " 'pula',\n",
       " 'pun',\n",
       " 'punya',\n",
       " 'rasa',\n",
       " 'rasanya',\n",
       " 'rata',\n",
       " 'rupanya',\n",
       " 'saat',\n",
       " 'saatnya',\n",
       " 'saja',\n",
       " 'sajalah',\n",
       " 'saling',\n",
       " 'sama',\n",
       " 'sama-sama',\n",
       " 'sambil',\n",
       " 'sampai',\n",
       " 'sampai-sampai',\n",
       " 'sampaikan',\n",
       " 'sana',\n",
       " 'sangat',\n",
       " 'sangatlah',\n",
       " 'satu',\n",
       " 'saya',\n",
       " 'sayalah',\n",
       " 'se',\n",
       " 'sebab',\n",
       " 'sebabnya',\n",
       " 'sebagai',\n",
       " 'sebagaimana',\n",
       " 'sebagainya',\n",
       " 'sebagian',\n",
       " 'sebaik',\n",
       " 'sebaik-baiknya',\n",
       " 'sebaiknya',\n",
       " 'sebaliknya',\n",
       " 'sebanyak',\n",
       " 'sebegini',\n",
       " 'sebegitu',\n",
       " 'sebelum',\n",
       " 'sebelumnya',\n",
       " 'sebenarnya',\n",
       " 'seberapa',\n",
       " 'sebesar',\n",
       " 'sebetulnya',\n",
       " 'sebisanya',\n",
       " 'sebuah',\n",
       " 'sebut',\n",
       " 'sebutlah',\n",
       " 'sebutnya',\n",
       " 'secara',\n",
       " 'secukupnya',\n",
       " 'sedang',\n",
       " 'sedangkan',\n",
       " 'sedemikian',\n",
       " 'sedikit',\n",
       " 'sedikitnya',\n",
       " 'seenaknya',\n",
       " 'segala',\n",
       " 'segalanya',\n",
       " 'segera',\n",
       " 'seharusnya',\n",
       " 'sehingga',\n",
       " 'seingat',\n",
       " 'sejak',\n",
       " 'sejauh',\n",
       " 'sejenak',\n",
       " 'sejumlah',\n",
       " 'sekadar',\n",
       " 'sekadarnya',\n",
       " 'sekali',\n",
       " 'sekali-kali',\n",
       " 'sekalian',\n",
       " 'sekaligus',\n",
       " 'sekalipun',\n",
       " 'sekarang',\n",
       " 'sekarang',\n",
       " 'sekecil',\n",
       " 'seketika',\n",
       " 'sekiranya',\n",
       " 'sekitar',\n",
       " 'sekitarnya',\n",
       " 'sekurang-kurangnya',\n",
       " 'sekurangnya',\n",
       " 'sela',\n",
       " 'selain',\n",
       " 'selaku',\n",
       " 'selalu',\n",
       " 'selama',\n",
       " 'selama-lamanya',\n",
       " 'selamanya',\n",
       " 'selanjutnya',\n",
       " 'seluruh',\n",
       " 'seluruhnya',\n",
       " 'semacam',\n",
       " 'semakin',\n",
       " 'semampu',\n",
       " 'semampunya',\n",
       " 'semasa',\n",
       " 'semasih',\n",
       " 'semata',\n",
       " 'semata-mata',\n",
       " 'semaunya',\n",
       " 'sementara',\n",
       " 'semisal',\n",
       " 'semisalnya',\n",
       " 'sempat',\n",
       " 'semua',\n",
       " 'semuanya',\n",
       " 'semula',\n",
       " 'sendiri',\n",
       " 'sendirian',\n",
       " 'sendirinya',\n",
       " 'seolah',\n",
       " 'seolah-olah',\n",
       " 'seorang',\n",
       " 'sepanjang',\n",
       " 'sepantasnya',\n",
       " 'sepantasnyalah',\n",
       " 'seperlunya',\n",
       " 'seperti',\n",
       " 'sepertinya',\n",
       " 'sepihak',\n",
       " 'sering',\n",
       " 'seringnya',\n",
       " 'serta',\n",
       " 'serupa',\n",
       " 'sesaat',\n",
       " 'sesama',\n",
       " 'sesampai',\n",
       " 'sesegera',\n",
       " 'sesekali',\n",
       " 'seseorang',\n",
       " 'sesuatu',\n",
       " 'sesuatunya',\n",
       " 'sesudah',\n",
       " 'sesudahnya',\n",
       " 'setelah',\n",
       " 'setempat',\n",
       " 'setengah',\n",
       " 'seterusnya',\n",
       " 'setiap',\n",
       " 'setiba',\n",
       " 'setibanya',\n",
       " 'setidak-tidaknya',\n",
       " 'setidaknya',\n",
       " 'setinggi',\n",
       " 'seusai',\n",
       " 'sewaktu',\n",
       " 'siap',\n",
       " 'siapa',\n",
       " 'siapakah',\n",
       " 'siapapun',\n",
       " 'sini',\n",
       " 'sinilah',\n",
       " 'soal',\n",
       " 'soalnya',\n",
       " 'suatu',\n",
       " 'sudah',\n",
       " 'sudahkah',\n",
       " 'sudahlah',\n",
       " 'supaya',\n",
       " 'tadi',\n",
       " 'tadinya',\n",
       " 'tahu',\n",
       " 'tahun',\n",
       " 'tak',\n",
       " 'tambah',\n",
       " 'tambahnya',\n",
       " 'tampak',\n",
       " 'tampaknya',\n",
       " 'tandas',\n",
       " 'tandasnya',\n",
       " 'tanpa',\n",
       " 'tanya',\n",
       " 'tanyakan',\n",
       " 'tanyanya',\n",
       " 'tapi',\n",
       " 'tegas',\n",
       " 'tegasnya',\n",
       " 'telah',\n",
       " 'tempat',\n",
       " 'tengah',\n",
       " 'tentang',\n",
       " 'tentu',\n",
       " 'tentulah',\n",
       " 'tentunya',\n",
       " 'tepat',\n",
       " 'terakhir',\n",
       " 'terasa',\n",
       " 'terbanyak',\n",
       " 'terdahulu',\n",
       " 'terdapat',\n",
       " 'terdiri',\n",
       " 'terhadap',\n",
       " 'terhadapnya',\n",
       " 'teringat',\n",
       " 'teringat-ingat',\n",
       " 'terjadi',\n",
       " 'terjadilah',\n",
       " 'terjadinya',\n",
       " 'terkira',\n",
       " 'terlalu',\n",
       " 'terlebih',\n",
       " 'terlihat',\n",
       " 'termasuk',\n",
       " 'ternyata',\n",
       " 'tersampaikan',\n",
       " 'tersebut',\n",
       " 'tersebutlah',\n",
       " 'tertentu',\n",
       " 'tertuju',\n",
       " 'terus',\n",
       " 'terutama',\n",
       " 'tetap',\n",
       " 'tetapi',\n",
       " 'tiap',\n",
       " 'tiba',\n",
       " 'tiba-tiba',\n",
       " 'tidak',\n",
       " 'tidakkah',\n",
       " 'tidaklah',\n",
       " 'tiga',\n",
       " 'tinggi',\n",
       " 'toh',\n",
       " 'tunjuk',\n",
       " 'turut',\n",
       " 'tutur',\n",
       " 'tuturnya',\n",
       " 'ucap',\n",
       " 'ucapnya',\n",
       " 'ujar',\n",
       " 'ujarnya',\n",
       " 'umum',\n",
       " 'umumnya',\n",
       " 'ungkap',\n",
       " 'ungkapnya',\n",
       " 'untuk',\n",
       " 'usah',\n",
       " 'usai',\n",
       " 'waduh',\n",
       " 'wah',\n",
       " 'wahai',\n",
       " 'waktu',\n",
       " 'waktunya',\n",
       " 'walau',\n",
       " 'walaupun',\n",
       " 'wong',\n",
       " 'yaitu',\n",
       " 'yakin',\n",
       " 'yakni',\n",
       " 'yang']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokenized_text):\n",
    "    \n",
    "    cleaned_token = []\n",
    "    for token in tokenized_text:\n",
    "        if token not in stopwords:\n",
    "            cleaned_token.append(token)\n",
    "            \n",
    "    return cleaned_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budi dan Badu bermain bola di sekolah\n",
      "['budi', 'dan', 'badu', 'bermain', 'bola', 'di', 'sekolah']\n",
      "['budi', 'badu', 'bermain', 'bola', 'sekolah']\n"
     ]
    }
   ],
   "source": [
    "result01 = tokenize_clean(string01)\n",
    "result1 = remove_stopwords(result01)\n",
    "print(string01)\n",
    "print(result01)\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apakah Romi dan Julia saling mencintai saat mereka berjumpa di persimpangan jalan?\n",
      "['budi', 'dan', 'badu', 'bermain', 'bola', 'di', 'sekolah']\n",
      "['budi', 'badu', 'bermain', 'bola', 'sekolah']\n"
     ]
    }
   ],
   "source": [
    "result02 = tokenize_clean(string01)\n",
    "result2 = remove_stopwords(result01)\n",
    "print(string02)\n",
    "print(result02)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming_text(tokenized_text):\n",
    "    \n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    \n",
    "    stems = []\n",
    "    for token in tokenized_text:\n",
    "        stems.append(stemmer.stem(token))\n",
    "        \n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budi dan Badu bermain bola di sekolah\n",
      "['budi', 'dan', 'badu', 'bermain', 'bola', 'di', 'sekolah']\n",
      "['budi', 'badu', 'bermain', 'bola', 'sekolah']\n",
      "['budi', 'badu', 'main', 'bola', 'sekolah']\n"
     ]
    }
   ],
   "source": [
    "result01 = tokenize_clean(string01)\n",
    "result1 = remove_stopwords(result01)\n",
    "stem_result1 = stemming_text(result1)\n",
    "print(string01)\n",
    "print(result01)\n",
    "print(result1)\n",
    "print(stem_result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apakah Romi dan Julia saling mencintai saat mereka berjumpa di persimpangan jalan?\n",
      "['apakah', 'romi', 'dan', 'julia', 'saling', 'mencintai', 'saat', 'mereka', 'berjumpa', 'di', 'persimpangan', 'jalan']\n",
      "['romi', 'julia', 'mencintai', 'berjumpa', 'persimpangan', 'jalan']\n",
      "['romi', 'julia', 'cinta', 'jumpa', 'simpang', 'jalan']\n"
     ]
    }
   ],
   "source": [
    "result02 = tokenize_clean(string02)\n",
    "result2 = remove_stopwords(result02)\n",
    "stem_result2 = stemming_text(result2)\n",
    "print(string02)\n",
    "print(result02)\n",
    "print(result2)\n",
    "print(stem_result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    \n",
    "    prep01 = tokenize_clean(text)\n",
    "    prep02 = remove_stopwords(prep01)\n",
    "    prep03 = stemming_text(prep02)\n",
    "    \n",
    "    return prep03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['romi', 'julia', 'cinta', 'jumpa', 'simpang', 'jalan']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocessing(string02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['budi', 'badu', 'main', 'bola', 'sekolah']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocessing(string01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "     'kucing kucing kucing hitam putih belang',\n",
    "     'tikus belang',\n",
    "     'tikus hitam',\n",
    "     'tikus tikus tikus'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tikus belang'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=True)\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['belang', 'hitam', 'kucing', 'putih', 'tikus']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.23513012 0.23513012 0.89469821 0.29823274 0.        ]\n",
      " [0.77722116 0.         0.         0.         0.62922751]\n",
      " [0.         0.77722116 0.         0.         0.62922751]\n",
      " [0.         0.         0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.2351301157996824\n",
      "  (0, 3)\t0.2982327375202219\n",
      "  (0, 1)\t0.2351301157996824\n",
      "  (0, 2)\t0.8946982125606657\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.23513012 0.23513012 0.89469821 0.29823274 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X[0].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>hitam</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kucing</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>putih</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tikus</td>\n",
       "      <td>0.629228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>belang</td>\n",
       "      <td>0.777221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TF-IDF\n",
       "hitam   0.000000\n",
       "kucing  0.000000\n",
       "putih   0.000000\n",
       "tikus   0.629228\n",
       "belang  0.777221"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X[1].T.todense(), index=vectorizer.get_feature_names(), columns=['TF-IDF'])\n",
    "df.sort_values(by=['TF-IDF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tikus</td>\n",
       "      <td>1.223144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>belang</td>\n",
       "      <td>1.510826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hitam</td>\n",
       "      <td>1.510826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kucing</td>\n",
       "      <td>1.916291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>putih</td>\n",
       "      <td>1.916291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             idf\n",
       "tikus   1.223144\n",
       "belang  1.510826\n",
       "hitam   1.510826\n",
       "kucing  1.916291\n",
       "putih   1.916291"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_idf = pd.DataFrame(vectorizer.idf_, index=vectorizer.get_feature_names(), columns=['idf'])\n",
    "df_idf.sort_values(by=['idf'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"Kambing hitam\"\n",
    "response = vectorizer.transform([str1])\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['belang', 'hitam', 'kucing', 'putih', 'tikus']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "files.append(\"Sekelompok ibu dan kaum perempuan duduk beralaskan rumput lapangan sambil fokus menganyam bambu yang ia genggam ditangan.\")\n",
    "files.append(\"Sebagian besar masyarakat rupanya tak mau melewatkan waktu begitu  saja untuk meratapi erupsi.\")\n",
    "files.append(\"Lombok memang memiliki sejuta pesona yang mampu menyedot perhatian orang untuk datang berwisata.\")\n",
    "files.append(\"Perempuan yang bergelut di dunia kerelawanan akan belajar caranya bertanggung jawab bagi sendiri dan orang lain.\")\n",
    "files.append(\"Kami berkoordinasi dan melapor pada posko relawan, kami berkomitmen  siap membantu dengan siaga 24 jam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file0': 'Sekelompok ibu dan kaum perempuan duduk beralaskan rumput lapangan sambil fokus menganyam bambu yang ia genggam ditangan.',\n",
       " 'file1': 'Sebagian besar masyarakat rupanya tak mau melewatkan waktu begitu  saja untuk meratapi erupsi.',\n",
       " 'file2': 'Lombok memang memiliki sejuta pesona yang mampu menyedot perhatian orang untuk datang berwisata.',\n",
       " 'file3': 'Perempuan yang bergelut di dunia kerelawanan akan belajar caranya bertanggung jawab bagi sendiri dan orang lain.',\n",
       " 'file4': 'Kami berkoordinasi dan melapor pada posko relawan, kami berkomitmen  siap membantu dengan siaga 24 jam'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dict = {}\n",
    "i = 0\n",
    "for t in files:\n",
    "    filename = \"file\" + str(i)\n",
    "    token_dict[filename] = t\n",
    "    i = i + 1\n",
    "\n",
    "token_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['Sekelompok ibu dan kaum perempuan duduk beralaskan rumput lapangan sambil fokus menganyam bambu yang ia genggam ditangan.', 'Sebagian besar masyarakat rupanya tak mau melewatkan waktu begitu  saja untuk meratapi erupsi.', 'Lombok memang memiliki sejuta pesona yang mampu menyedot perhatian orang untuk datang berwisata.', 'Perempuan yang bergelut di dunia kerelawanan akan belajar caranya bertanggung jawab bagi sendiri dan orang lain.', 'Kami berkoordinasi dan melapor pada posko relawan, kami berkomitmen  siap membantu dengan siaga 24 jam'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sekelompok ibu dan kaum perempuan duduk beralaskan rumput lapangan sambil fokus menganyam bambu yang ia genggam ditangan.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dict['file0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform tf-idf vectorization\n",
    "tfidf = TfidfVectorizer(max_df=0.8,             # terms with document frequency value > 0.8 will be removed\n",
    "                        min_df=0.2,             # terms with document frequency value < 0.2 will be removed\n",
    "                        max_features=200000,    # create maximum 200.000 vocabulary that only consider the top max_features ordered by term frequency across the corpus.\n",
    "                        stop_words = stopwords, # stopwords list\n",
    "                        use_idf=True,           # enable inverse-document-frequency reweighting\n",
    "                        tokenizer=text_preprocessing, # override the string tokenization step by using text_prepocessing function \n",
    "                        ngram_range=(1,3))      # ngram range 1 - 3 \n",
    "\n",
    "\n",
    "tfs = tfidf.fit_transform(token_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 96)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 11)\t0.17500574860015006\n",
      "  (0, 8)\t0.17500574860015006\n",
      "  (0, 24)\t0.17500574860015006\n",
      "  (0, 48)\t0.17500574860015006\n",
      "  (0, 86)\t0.17500574860015006\n",
      "  (0, 5)\t0.17500574860015006\n",
      "  (0, 17)\t0.17500574860015006\n",
      "  (0, 65)\t0.17500574860015006\n",
      "  (0, 36)\t0.17500574860015006\n",
      "  (0, 39)\t0.17500574860015006\n",
      "  (0, 29)\t0.17500574860015006\n",
      "  (0, 10)\t0.17500574860015006\n",
      "  (0, 7)\t0.17500574860015006\n",
      "  (0, 23)\t0.17500574860015006\n",
      "  (0, 47)\t0.17500574860015006\n",
      "  (0, 85)\t0.17500574860015006\n",
      "  (0, 4)\t0.17500574860015006\n",
      "  (0, 16)\t0.17500574860015006\n",
      "  (0, 64)\t0.17500574860015006\n",
      "  (0, 35)\t0.17500574860015006\n",
      "  (0, 38)\t0.17500574860015006\n",
      "  (0, 92)\t0.17500574860015006\n",
      "  (0, 28)\t0.17500574860015006\n",
      "  (0, 9)\t0.17500574860015006\n",
      "  (0, 6)\t0.17500574860015006\n",
      "  (0, 22)\t0.17500574860015006\n",
      "  (0, 46)\t0.17500574860015006\n",
      "  (0, 84)\t0.17500574860015006\n",
      "  (0, 3)\t0.17500574860015006\n",
      "  (0, 15)\t0.17500574860015006\n",
      "  (0, 63)\t0.1411935360448027\n",
      "  (0, 34)\t0.17500574860015006\n",
      "  (0, 37)\t0.17500574860015006\n"
     ]
    }
   ],
   "source": [
    "print(tfs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ajar', 'ajar tanggung', 'ajar tanggung orang', 'alas', 'alas rumput', 'alas rumput lapang', 'anyam', 'anyam bambu', 'anyam bambu genggam', 'bambu', 'bambu genggam', 'bambu genggam tang', 'bantu', 'bantu siaga', 'bantu siaga jam', 'duduk', 'duduk alas', 'duduk alas rumput', 'dunia', 'dunia rawan', 'dunia rawan ajar', 'erupsi', 'fokus', 'fokus anyam', 'fokus anyam bambu', 'gelut', 'gelut dunia', 'gelut dunia rawan', 'genggam', 'genggam tang', 'jam', 'juta', 'juta pesona', 'juta pesona sedot', 'kaum', 'kaum perempuan', 'kaum perempuan duduk', 'kelompok', 'kelompok kaum', 'kelompok kaum perempuan', 'komitmen', 'komitmen bantu', 'komitmen bantu siaga', 'koordinasi', 'koordinasi lapor', 'koordinasi lapor posko', 'lapang', 'lapang fokus', 'lapang fokus anyam', 'lapor', 'lapor posko', 'lapor posko rawan', 'lombok', 'lombok milik', 'lombok milik juta', 'masyarakat', 'masyarakat ratap', 'masyarakat ratap erupsi', 'milik', 'milik juta', 'milik juta pesona', 'orang', 'orang wisata', 'perempuan', 'perempuan duduk', 'perempuan duduk alas', 'perempuan gelut', 'perempuan gelut dunia', 'perhati', 'perhati orang', 'perhati orang wisata', 'pesona', 'pesona sedot', 'pesona sedot perhati', 'posko', 'posko rawan', 'posko rawan komitmen', 'ratap', 'ratap erupsi', 'rawan', 'rawan ajar', 'rawan ajar tanggung', 'rawan komitmen', 'rawan komitmen bantu', 'rumput', 'rumput lapang', 'rumput lapang fokus', 'sedot', 'sedot perhati', 'sedot perhati orang', 'siaga', 'siaga jam', 'tang', 'tanggung', 'tanggung orang', 'wisata']\n"
     ]
    }
   ],
   "source": [
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>rawan</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>perempuan</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>orang</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ajar</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>perhati</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gelut dunia rawan</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gelut dunia</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gelut</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tanggung orang</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wisata</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        idf\n",
       "rawan              1.693147\n",
       "perempuan          1.693147\n",
       "orang              1.693147\n",
       "ajar               2.098612\n",
       "perhati            2.098612\n",
       "...                     ...\n",
       "gelut dunia rawan  2.098612\n",
       "gelut dunia        2.098612\n",
       "gelut              2.098612\n",
       "tanggung orang     2.098612\n",
       "wisata             2.098612\n",
       "\n",
       "[96 rows x 1 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_idf = pd.DataFrame(tfidf.idf_, index=feature_names,columns=[\"idf\"])\n",
    "df_idf.sort_values(by=['idf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
